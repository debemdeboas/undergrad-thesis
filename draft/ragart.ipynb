{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Settings, PromptTemplate\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.readers.file import PyMuPDFReader\n",
    "from llama_index.core.node_parser import HierarchicalNodeParser\n",
    "\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "pdf_loader = PyMuPDFReader()\n",
    "base_path = '../articles'\n",
    "\n",
    "documents = []\n",
    "for file in glob.glob(base_path + '/*.pdf', recursive=True):\n",
    "    documents.extend(pdf_loader.load_data(file))\n",
    "\n",
    "documents.extend(pdf_loader.load_data('../monografia/main.pdf'))\n",
    "\n",
    "# documents = []\n",
    "# documents = SimpleDirectoryReader('../articles', recursive=True).load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/debem/mambaforge/envs/ml-gpu/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "Settings.embed_model = HuggingFaceEmbedding(\"BAAI/bge-m3\")\n",
    "Settings.llm = Ollama(model=\"llama3\", request_timeout=360.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter, HierarchicalNodeParser\n",
    "\n",
    "node_parser = HierarchicalNodeParser.from_defaults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = node_parser.get_nodes_from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define storage context\n",
    "from llama_index.core.storage.docstore import SimpleDocumentStore\n",
    "from llama_index.core import StorageContext\n",
    "\n",
    "docstore = SimpleDocumentStore()\n",
    "\n",
    "# insert nodes into docstore\n",
    "docstore.add_documents(nodes)\n",
    "\n",
    "# define storage context (will include vector store by default too)\n",
    "storage_context = StorageContext.from_defaults(docstore=docstore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load index into vector index\n",
    "from llama_index.core.node_parser import get_leaf_nodes, get_root_nodes\n",
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "leaf_nodes = get_leaf_nodes(nodes)\n",
    "root_nodes = get_root_nodes(nodes)\n",
    "\n",
    "base_index = VectorStoreIndex(\n",
    "    leaf_nodes,\n",
    "    storage_context=storage_context,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.retrievers import AutoMergingRetriever\n",
    "\n",
    "base_retriever = base_index.as_retriever(similarity_top_k=6)\n",
    "retriever = AutoMergingRetriever(base_retriever, storage_context, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "\n",
    "query_engine = RetrieverQueryEngine.from_args(retriever)\n",
    "base_query_engine = RetrieverQueryEngine.from_args(base_retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_str = (\n",
    "    'You are an academic reviewer and you\\'ll be helping me critique a paper. '\n",
    "    'Using main.pdf as the paper, please provide a critique of the paper. '\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = query_engine.query(query_str)\n",
    "base_response = base_query_engine.query(query_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided manuscript (main.pdf), I will offer my critique.\n",
      "\n",
      "Overall, the manuscript is well-organized and easy to follow. The authors' core contributions are evident in their comprehensive survey of large language models. One of the most notable strengths is the thoroughness with which they cover the current state of research in this field. Multiple reviewers praised the paper's clarity and coherence, making it accessible to a broad audience.\n",
      "\n",
      "However, some common weaknesses mentioned by reviewers include the lack of depth in certain sections and the need for more nuanced analysis in others. To improve the paper, I would suggest providing more concrete examples to illustrate key concepts and expanding on the implications of the findings.\n",
      "\n",
      "As for missing references, one reviewer noted that the authors could have incorporated additional sources to further support their claims. Another reviewer suggested exploring similar topics in other fields or disciplines to provide a more comprehensive understanding.\n",
      "\n",
      "In conclusion, while there are areas for improvement, the manuscript presents a solid foundation for future research and provides valuable insights into the current state of large language models.\n",
      "---\n",
      "Based on the provided context, it appears that the paper \"A Survey of Large Language Models\" is being reviewed. As an academic reviewer, I will provide a critique of this paper.\n",
      "\n",
      "**Core contributions:** The manuscript provides a comprehensive survey of large language models, which is an important contribution to the field. However, the paper would benefit from more in-depth analysis and discussion of the implications of these models.\n",
      "\n",
      "**Common strengths:** One of the strengths of the work is its ability to provide a broad overview of the current state of research in this area. The manuscript is well-organized and easy to follow.\n",
      "\n",
      "**Common weaknesses:** One weakness of the paper is that it may be too general and lacks specific examples or case studies to illustrate the concepts discussed. Additionally, some reviewers noted that the manuscript could benefit from more rigorous evaluation of the models surveyed.\n",
      "\n",
      "**Suggestions for improvement:** To improve this paper, I would suggest providing more concrete examples of how large language models can be applied in different domains. Additionally, the authors should consider including a more detailed discussion of the limitations and potential pitfalls of these models.\n",
      "\n",
      "**Missing references:** It appears that some reviewers noted the absence of certain references, particularly those related to the application of large language models in specific fields or industries.\n",
      "\n",
      "Please note that this critique is based solely on the provided context and not prior knowledge.\n"
     ]
    }
   ],
   "source": [
    "print(str(response))\n",
    "print('---')\n",
    "print(str(base_response))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
